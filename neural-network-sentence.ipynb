{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "\n",
    "class ActivationFuction(Enum):\n",
    "    SIGMOID = 1\n",
    "    RELU = 2,\n",
    "    ELU = 3 # a = 1\n",
    "\n",
    "class Problem(Enum):\n",
    "    Classification = 1,\n",
    "    Regression = 2\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, \n",
    "                 input_size = 784, \n",
    "                 hidden_size = 128, \n",
    "                 output_size = 10, \n",
    "                 hidden_layers_count = 1, \n",
    "                 inner_activation_function = ActivationFuction.SIGMOID,\n",
    "                 problem = Problem.Classification,\n",
    "                 learning_rate = 0.01, \n",
    "                 num_epochs = 10, \n",
    "                 seed = 0, \n",
    "                 use_bias = True,\n",
    "                 visualize = False) -> None:\n",
    "        self.seed = seed\n",
    "        np.random.seed(self.seed)\n",
    "        self.use_bias = use_bias\n",
    "        self.hidden_layers_count = hidden_layers_count\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.visualize = visualize\n",
    "        \n",
    "        if problem == Problem.Regression:\n",
    "            self.output_size = 1\n",
    "            self.input_size = 1\n",
    "        else:\n",
    "            self.output_size = output_size\n",
    "            \n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.inner_activation_function = inner_activation_function\n",
    "        self.problem = problem\n",
    " \n",
    "        self.layers_sizes = [self.input_size] + [self.hidden_size] * self.hidden_layers_count + [self.output_size]\n",
    "        self.layers_count = len(self.layers_sizes)\n",
    "        self.weights_count = self.layers_count - 1\n",
    "\n",
    "        self.weights = [None] * self.weights_count \n",
    "        self.bias = [None] * self.weights_count \n",
    "        self.create_weights_array()\n",
    "\n",
    "    def create_weights_array(self):\n",
    "        for i in range(self.weights_count):\n",
    "            if self.inner_activation_function == ActivationFuction.SIGMOID:\n",
    "                self.weights[i] = np.random.uniform(-np.sqrt(6 / (self.layers_sizes[i] + self.layers_sizes[i + 1])), np.sqrt(6 / (self.layers_sizes[i] + self.layers_sizes[i + 1])), size=(self.layers_sizes[i], self.layers_sizes[i + 1]))\n",
    "            else:\n",
    "                self.weights[i] = np.random.normal(0, np.sqrt(2 / (self.layers_sizes[i] + self.layers_sizes[i + 1])), size=(self.layers_sizes[i], self.layers_sizes[i + 1]))\n",
    "    \n",
    "            if self.use_bias:\n",
    "                self.bias[i] = np.zeros(self.layers_sizes[i + 1])\n",
    "                \n",
    "    def train_and_check_acc(self, train_inputs, train_results, test_inputs, test_results):\n",
    "    \n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i in range(len(train_inputs)):\n",
    "                self.train(train_inputs[i], train_results[i])\n",
    "                \n",
    "            if(self.visualize):\n",
    "                    fig = plt.figure(figsize = (20, 12)) # width x height\n",
    "                    for i in range(self.weights_count):\n",
    "                        ax1 = fig.add_subplot(3, 5, i+1) # row, column, position\n",
    "                        sns.heatmap(self.weights[i], cmap=\"coolwarm\", ax=ax1) # jaka paleta? moze Spectral albo magma?\n",
    "                        plt.title(f'Weight Heatmap - Layers {i}-{i+1}')\n",
    "                        mean = np.mean(self.weights[i])\n",
    "                        std = np.std(self.weights[i])\n",
    "                        print(f'Layers {i}-{i+1}: Mean={mean}, Std={std}')\n",
    "                    plt.show()\n",
    "                        \n",
    "                \n",
    "            correct = 0\n",
    "            nn_results = []\n",
    "            for i in range(len(test_inputs)):\n",
    "                values = self.predict(test_inputs[i])\n",
    "                nn_results.append(values[-1])\n",
    "                \n",
    "                if (self.problem == Problem.Classification):  \n",
    "                   if np.argmax(values[-1]) == np.argmax(test_results[i]):\n",
    "                        correct += 1\n",
    "                        \n",
    "            error = self.accuracy(nn_results, test_results)  \n",
    "            if (self.problem == Problem.Classification):\n",
    "                test_accuracy = correct / len(test_inputs)\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}, Test Accuracy: {test_accuracy * 100:.2f}% Loss: {error}, Correct: {correct}, All: {len(test_inputs)} \")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}, Test Accuracy: {error}\")\n",
    "            \n",
    "    def accuracy(self, results, expected_result):\n",
    "        if self.problem == Problem.Classification:\n",
    "            return -np.sum(expected_result * np.log(results[-1]))\n",
    "        else:\n",
    "            return np.average(np.power(expected_result - results, 2))\n",
    "\n",
    "        \n",
    "    def train(self, input, expected_result): # Backpropagation\n",
    "        values = self.predict(input)\n",
    "    \n",
    "        delta = [None] * self.weights_count\n",
    "        delta[-1] = values[-1] - expected_result\n",
    "        \n",
    "        for weightId in range(self.weights_count - 2, -1, -1):\n",
    "            delta[weightId] = np.dot(delta[weightId + 1], self.weights[weightId + 1].T) * self.neuron_activation_derivative(values[weightId + 1])\n",
    "            \n",
    "        for weightId in range(self.weights_count):\n",
    "            self.weights[weightId] -= np.outer(values[weightId], delta[weightId]) * self.learning_rate \n",
    "            if self.use_bias:\n",
    "                self.bias[weightId] = self.bias[weightId] - delta[weightId] * self.learning_rate\n",
    "        \n",
    "    \n",
    "    def neuron_activation(self, v):\n",
    "        if self.inner_activation_function == ActivationFuction.SIGMOID:\n",
    "            return 1 / (1 + np.exp(-v))\n",
    "        elif self.inner_activation_function == ActivationFuction.RELU:\n",
    "            return np.maximum(0, v)\n",
    "        elif self.inner_activation_function == ActivationFuction.ELU:\n",
    "            return (v > 0) * 1 + (v <= 0) * np.exp(v) \n",
    "        \n",
    "    def neuron_activation_derivative(self, v):\n",
    "        if self.inner_activation_function == ActivationFuction.SIGMOID:\n",
    "            return v * (1 - v)\n",
    "        elif self.inner_activation_function == ActivationFuction.RELU:\n",
    "            return (v > 0) * 1\n",
    "        elif self.inner_activation_function == ActivationFuction.ELU:\n",
    "            return (v > 0) * v + (v <= 0) * (np.exp(v) - 1) \n",
    "    \n",
    "    def output_activation(self, x):\n",
    "        if self.problem == Problem.Classification:\n",
    "            exp_x = np.exp(x - np.max(x))\n",
    "            return exp_x / exp_x.sum()\n",
    "        else: \n",
    "            return x\n",
    "    \n",
    "    def predict(self, input): #forward propagation\n",
    "        values = [None] * self.layers_count\n",
    "        \n",
    "        values[0] = input\n",
    "        \n",
    "        for weightId in range(self.weights_count):\n",
    "           v = np.dot(values[weightId], self.weights[weightId]) + self.bias[weightId] if self.use_bias else 0\n",
    "           if weightId != self.weights_count - 1:\n",
    "               v = self.neuron_activation(v)\n",
    "           else:    \n",
    "               v = self.output_activation(v)\n",
    "               \n",
    "           values[weightId + 1] = v  \n",
    "        \n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Test Accuracy: 94.50% Loss: 148987.8099009454, Correct: 9450, All: 10000 \n",
      "Epoch 2/25, Test Accuracy: 95.80% Loss: 167702.38812139485, Correct: 9580, All: 10000 \n",
      "Epoch 3/25, Test Accuracy: 96.11% Loss: 186759.3588488006, Correct: 9611, All: 10000 \n",
      "Epoch 4/25, Test Accuracy: 96.72% Loss: 166758.24541385032, Correct: 9672, All: 10000 \n",
      "Epoch 5/25, Test Accuracy: 95.99% Loss: 217420.3514042992, Correct: 9599, All: 10000 \n",
      "Epoch 6/25, Test Accuracy: 96.82% Loss: 186973.5694611423, Correct: 9682, All: 10000 \n",
      "Epoch 7/25, Test Accuracy: 97.11% Loss: 172315.7261019609, Correct: 9711, All: 10000 \n",
      "Epoch 8/25, Test Accuracy: 97.09% Loss: 244473.95129345375, Correct: 9709, All: 10000 \n",
      "Epoch 9/25, Test Accuracy: 96.61% Loss: 226466.33684788237, Correct: 9661, All: 10000 \n",
      "Epoch 10/25, Test Accuracy: 96.95% Loss: 248806.8844620203, Correct: 9695, All: 10000 \n",
      "Epoch 11/25, Test Accuracy: 97.12% Loss: 251131.37381312042, Correct: 9712, All: 10000 \n",
      "Epoch 12/25, Test Accuracy: 97.30% Loss: 287672.9713307075, Correct: 9730, All: 10000 \n",
      "Epoch 13/25, Test Accuracy: 97.24% Loss: 326820.2490751922, Correct: 9724, All: 10000 \n",
      "Epoch 14/25, Test Accuracy: 97.29% Loss: 435685.86246105144, Correct: 9729, All: 10000 \n",
      "Epoch 15/25, Test Accuracy: 97.17% Loss: 435895.7406980269, Correct: 9717, All: 10000 \n",
      "Epoch 16/25, Test Accuracy: 97.35% Loss: 327215.5143844178, Correct: 9735, All: 10000 \n",
      "Epoch 17/25, Test Accuracy: 97.49% Loss: 378234.41214690864, Correct: 9749, All: 10000 \n",
      "Epoch 18/25, Test Accuracy: 97.39% Loss: 404314.07193283556, Correct: 9739, All: 10000 \n",
      "Epoch 19/25, Test Accuracy: 97.11% Loss: 438573.2536896142, Correct: 9711, All: 10000 \n",
      "Epoch 20/25, Test Accuracy: 96.97% Loss: 386760.91789413, Correct: 9697, All: 10000 \n",
      "Epoch 21/25, Test Accuracy: 97.16% Loss: 559839.3287841156, Correct: 9716, All: 10000 \n",
      "Epoch 22/25, Test Accuracy: 97.50% Loss: 515551.520626976, Correct: 9750, All: 10000 \n",
      "Epoch 23/25, Test Accuracy: 97.44% Loss: 530437.7253394308, Correct: 9744, All: 10000 \n",
      "Epoch 24/25, Test Accuracy: 97.47% Loss: 488879.7983718862, Correct: 9747, All: 10000 \n",
      "Epoch 25/25, Test Accuracy: 97.14% Loss: 351749.9763731969, Correct: 9714, All: 10000 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mnist.loader import MNIST\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mndata = MNIST(\"C:\\\\Users\\\\jkobo\\\\source\\\\repos\\\\sn1\\\\mnist-digit-recognition\\\\data\")  # Replace with the path to your MNIST data\n",
    "mndata.gz = True\n",
    "\n",
    "# Load the training and testing data\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "# Convert to NumPy arrays for easier manipulation\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "train_labels = np.eye(num_classes)[train_labels]\n",
    "test_labels = np.eye(num_classes)[test_labels]\n",
    "\n",
    "nn = NeuralNetwork(num_epochs=25, hidden_layers_count=4, hidden_size=78,  inner_activation_function = ActivationFuction.RELU)\n",
    "\n",
    "nn.train_and_check_acc(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.simple.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.simple.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 2\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nn = NeuralNetwork(input_size = 2, output_size = num_classes, hidden_size = 2, hidden_layers_count = 4, num_epochs = 3, inner_activation_function = ActivationFuction.RELU, visualize=True)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.simple.test.10000.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.simple.train.10000.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 2\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nn = NeuralNetwork(input_size = 2, output_size = num_classes, hidden_size = 2, hidden_layers_count = 4, num_epochs = 5, inner_activation_function = ActivationFuction.SIGMOID)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.three_gauss.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.three_gauss.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 3\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nn = NeuralNetwork(input_size = 2, output_size = num_classes, hidden_size = 10, hidden_layers_count = 1, num_epochs = 25, learning_rate=0.0001, inner_activation_function = ActivationFuction.RELU, visualize=True)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"regression/data.cube.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"regression/data.cube.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[\"x\"])\n",
    "train_results = np.array(train[\"y\"])\n",
    "test_vectors = np.array(test[\"x\"])\n",
    "test_results = np.array(test[\"y\"])\n",
    "\n",
    "nn = NeuralNetwork(hidden_size = 6, hidden_layers_count = 1, num_epochs = 20, inner_activation_function = ActivationFuction.RELU, problem = Problem.Regression)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
