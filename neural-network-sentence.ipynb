{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "class ActivationFuction(Enum):\n",
    "    SIGMOID = 1\n",
    "    RELU = 2,\n",
    "    ELU = 3 # a = 1\n",
    "\n",
    "class Problem(Enum):\n",
    "    Classification = 1,\n",
    "    Regression = 2\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, \n",
    "                 input_size = 784, \n",
    "                 hidden_size = 128, \n",
    "                 output_size = 10, \n",
    "                 hidden_layers_count = 1, \n",
    "                 inner_activation_function = ActivationFuction.SIGMOID,\n",
    "                 problem = Problem.Classification,\n",
    "                 learning_rate = 0.01, \n",
    "                 num_epochs = 10, \n",
    "                 seed = 0, \n",
    "                 use_bias = True) -> None:\n",
    "        self.seed = seed\n",
    "        np.random.seed(self.seed)\n",
    "        self.use_bias = use_bias\n",
    "        self.hidden_layers_count = hidden_layers_count\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if problem == Problem.Regression:\n",
    "            self.output_size = 1\n",
    "            self.input_size = 1\n",
    "        else:\n",
    "            self.output_size = output_size\n",
    "            \n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.inner_activation_function = inner_activation_function\n",
    "        self.problem = problem\n",
    " \n",
    "        self.layers_sizes = [self.input_size] + [self.hidden_size] * self.hidden_layers_count + [self.output_size]\n",
    "        self.layers_count = len(self.layers_sizes)\n",
    "        self.weights_count = self.layers_count - 1\n",
    "\n",
    "        self.weights = [None] * self.weights_count \n",
    "        self.bias = [None] * self.weights_count \n",
    "        self.create_weights_array()\n",
    "\n",
    "    def create_weights_array(self):\n",
    "        for i in range(self.weights_count):\n",
    "            if self.inner_activation_function == ActivationFuction.SIGMOID:\n",
    "                self.weights[i] = np.random.uniform(-np.sqrt(6 / (self.layers_sizes[i] + self.layers_sizes[i + 1])), np.sqrt(6 / (self.layers_sizes[i] + self.layers_sizes[i + 1])), size=(self.layers_sizes[i], self.layers_sizes[i + 1]))\n",
    "            else:\n",
    "                self.weights[i] = np.random.normal(0, np.sqrt(2 / (self.layers_sizes[i] + self.layers_sizes[i + 1])), size=(self.layers_sizes[i], self.layers_sizes[i + 1]))\n",
    "    \n",
    "            if self.use_bias:\n",
    "                self.bias[i] = np.zeros(self.layers_sizes[i + 1])\n",
    "                \n",
    "    def train_and_check_acc(self, train_inputs, train_results, test_inputs, test_results):\n",
    "    \n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i in range(len(train_inputs)):\n",
    "                self.train(train_inputs[i], train_results[i])\n",
    "                \n",
    "            correct = 0\n",
    "            nn_results = []\n",
    "            for i in range(len(test_inputs)):\n",
    "                values = self.predict(test_inputs[i])\n",
    "                nn_results.append(values[-1])\n",
    "                \n",
    "                if (self.problem == Problem.Classification):  \n",
    "                   if np.argmax(values[-1]) == np.argmax(test_results[i]):\n",
    "                        correct += 1\n",
    "                        \n",
    "            error = self.accuracy(nn_results, test_results)  \n",
    "            if (self.problem == Problem.Classification):\n",
    "                test_accuracy = correct / len(test_inputs)\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}, Test Accuracy: {test_accuracy * 100:.2f}% Loss: {error}, Correct: {correct}, All: {len(test_inputs)} \")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}, Test Accuracy: {error}\")\n",
    "            \n",
    "    def accuracy(self, results, expected_result):\n",
    "        if self.problem == Problem.Classification:\n",
    "            return -np.sum(expected_result * np.log(results[-1]))\n",
    "        else:\n",
    "            return np.average(np.power(expected_result - results, 2))\n",
    "\n",
    "        \n",
    "    def train(self, input, expected_result): # Backpropagation\n",
    "        values = self.predict(input)\n",
    "    \n",
    "        delta = [None] * self.weights_count\n",
    "        delta[-1] = values[-1] - expected_result\n",
    "        \n",
    "        for weightId in range(self.weights_count - 2, -1, -1):\n",
    "            delta[weightId] = np.dot(delta[weightId + 1], self.weights[weightId + 1].T) * self.neuron_activation_derivative(values[weightId + 1])\n",
    "            \n",
    "        for weightId in range(self.weights_count):\n",
    "            self.weights[weightId] -= np.outer(values[weightId], delta[weightId]) * self.learning_rate \n",
    "            if self.use_bias:\n",
    "                self.bias[weightId] = self.bias[weightId] - delta[weightId] * self.learning_rate\n",
    "        \n",
    "    \n",
    "    def neuron_activation(self, v):\n",
    "        if self.inner_activation_function == ActivationFuction.SIGMOID:\n",
    "            return 1 / (1 + np.exp(-v))\n",
    "        elif self.inner_activation_function == ActivationFuction.RELU:\n",
    "            return np.maximum(0, v)\n",
    "        elif self.inner_activation_function == ActivationFuction.ELU:\n",
    "            return (v > 0) * 1 + (v <= 0) * np.exp(v) \n",
    "        \n",
    "    def neuron_activation_derivative(self, v):\n",
    "        if self.inner_activation_function == ActivationFuction.SIGMOID:\n",
    "            return v * (1 - v)\n",
    "        elif self.inner_activation_function == ActivationFuction.RELU:\n",
    "            return (v > 0) * 1\n",
    "        elif self.inner_activation_function == ActivationFuction.ELU:\n",
    "            return (v > 0) * v + (v <= 0) * (np.exp(v) - 1) \n",
    "    \n",
    "    def output_activation(self, x):\n",
    "        if self.problem == Problem.Classification:\n",
    "            exp_x = np.exp(x - np.max(x))\n",
    "            return exp_x / exp_x.sum()\n",
    "        else: \n",
    "            return x\n",
    "    \n",
    "    def predict(self, input): #forward propagation\n",
    "        values = [None] * self.layers_count\n",
    "        \n",
    "        values[0] = input\n",
    "        \n",
    "        for weightId in range(self.weights_count):\n",
    "           v = np.dot(values[weightId], self.weights[weightId]) + self.bias[weightId] if self.use_bias else 0\n",
    "           if weightId != self.weights_count - 1:\n",
    "               v = self.neuron_activation(v)\n",
    "           else:    \n",
    "               v = self.output_activation(v)\n",
    "               \n",
    "           values[weightId + 1] = v  \n",
    "        \n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "Epoch 1/10, Test Accuracy: 92.39% Loss: 109838.40205957575, Correct: 9239, All: 10000 \n",
      "Epoch 2/10, Test Accuracy: 94.60% Loss: 105290.46652658422, Correct: 9460, All: 10000 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muzyk\\sn_p1\\mnist-digit-recognition\\n-sentence.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m test_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meye(num_classes)[test_labels]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m nn \u001b[39m=\u001b[39m NeuralNetwork(inner_activation_function \u001b[39m=\u001b[39m ActivationFuction\u001b[39m.\u001b[39mSIGMOID)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m nn\u001b[39m.\u001b[39;49mtrain_and_check_acc(train_images, train_labels, test_images, test_labels)\n",
      "\u001b[1;32mc:\\Users\\muzyk\\sn_p1\\mnist-digit-recognition\\n-sentence.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(train_inputs)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(train_inputs[i], train_results[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     nn_results \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\muzyk\\sn_p1\\mnist-digit-recognition\\n-sentence.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, expected_result): \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     delta \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_count\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     delta[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m values[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m expected_result\n",
      "\u001b[1;32mc:\\Users\\muzyk\\sn_p1\\mnist-digit-recognition\\n-sentence.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m values[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39mfor\u001b[39;00m weightId \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_count):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m    v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(values[weightId], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[weightId]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias[weightId] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m    \u001b[39mif\u001b[39;00m weightId \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_count \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/muzyk/sn_p1/mnist-digit-recognition/n-sentence.ipynb#W1sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m        v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneuron_activation(v)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mnist.loader import MNIST\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mndata = MNIST(\"C:\\\\Users\\\\muzyk\\\\Downloads\\\\mnist\")  # Replace with the path to your MNIST data\n",
    "mndata.gz = True\n",
    "\n",
    "# Load the training and testing data\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "# Convert to NumPy arrays for easier manipulation\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "train_labels = np.eye(num_classes)[train_labels]\n",
    "test_labels = np.eye(num_classes)[test_labels]\n",
    "\n",
    "nn = NeuralNetwork(inner_activation_function = ActivationFuction.SIGMOID)\n",
    "\n",
    "nn.train_and_check_acc(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Test Accuracy: 47.00% Loss: 71.8848281868098, Correct: 47, All: 100 \n",
      "Epoch 2/100, Test Accuracy: 26.00% Loss: 69.36252357913196, Correct: 26, All: 100 \n",
      "Epoch 3/100, Test Accuracy: 37.00% Loss: 69.27108505166932, Correct: 37, All: 100 \n",
      "Epoch 4/100, Test Accuracy: 58.00% Loss: 69.37767267644239, Correct: 58, All: 100 \n",
      "Epoch 5/100, Test Accuracy: 79.00% Loss: 69.58103275522006, Correct: 79, All: 100 \n",
      "Epoch 6/100, Test Accuracy: 87.00% Loss: 69.87161060329402, Correct: 87, All: 100 \n",
      "Epoch 7/100, Test Accuracy: 93.00% Loss: 70.25529210047841, Correct: 93, All: 100 \n",
      "Epoch 8/100, Test Accuracy: 96.00% Loss: 70.74606537943043, Correct: 96, All: 100 \n",
      "Epoch 9/100, Test Accuracy: 98.00% Loss: 71.36254813836366, Correct: 98, All: 100 \n",
      "Epoch 10/100, Test Accuracy: 99.00% Loss: 72.12595343358063, Correct: 99, All: 100 \n",
      "Epoch 11/100, Test Accuracy: 99.00% Loss: 73.05849425231557, Correct: 99, All: 100 \n",
      "Epoch 12/100, Test Accuracy: 99.00% Loss: 74.18180069852662, Correct: 99, All: 100 \n",
      "Epoch 13/100, Test Accuracy: 99.00% Loss: 75.51529355432785, Correct: 99, All: 100 \n",
      "Epoch 14/100, Test Accuracy: 99.00% Loss: 77.07463374922142, Correct: 99, All: 100 \n",
      "Epoch 15/100, Test Accuracy: 99.00% Loss: 78.87043134631756, Correct: 99, All: 100 \n",
      "Epoch 16/100, Test Accuracy: 99.00% Loss: 80.90738709489528, Correct: 99, All: 100 \n",
      "Epoch 17/100, Test Accuracy: 99.00% Loss: 83.18397501894577, Correct: 99, All: 100 \n",
      "Epoch 18/100, Test Accuracy: 99.00% Loss: 85.69268098167571, Correct: 99, All: 100 \n",
      "Epoch 19/100, Test Accuracy: 99.00% Loss: 88.42071960796557, Correct: 99, All: 100 \n",
      "Epoch 20/100, Test Accuracy: 99.00% Loss: 91.35108601054048, Correct: 99, All: 100 \n",
      "Epoch 21/100, Test Accuracy: 99.00% Loss: 94.4637724210674, Correct: 99, All: 100 \n",
      "Epoch 22/100, Test Accuracy: 99.00% Loss: 97.7369912910716, Correct: 99, All: 100 \n",
      "Epoch 23/100, Test Accuracy: 99.00% Loss: 101.1482834883885, Correct: 99, All: 100 \n",
      "Epoch 24/100, Test Accuracy: 99.00% Loss: 104.67543734447324, Correct: 99, All: 100 \n",
      "Epoch 25/100, Test Accuracy: 99.00% Loss: 108.29718859934209, Correct: 99, All: 100 \n",
      "Epoch 26/100, Test Accuracy: 99.00% Loss: 111.99370524509902, Correct: 99, All: 100 \n",
      "Epoch 27/100, Test Accuracy: 99.00% Loss: 115.74688266027158, Correct: 99, All: 100 \n",
      "Epoch 28/100, Test Accuracy: 99.00% Loss: 119.54048460360178, Correct: 99, All: 100 \n",
      "Epoch 29/100, Test Accuracy: 99.00% Loss: 123.36016757785046, Correct: 99, All: 100 \n",
      "Epoch 30/100, Test Accuracy: 99.00% Loss: 127.19342295381577, Correct: 99, All: 100 \n",
      "Epoch 31/100, Test Accuracy: 99.00% Loss: 131.02946566050727, Correct: 99, All: 100 \n",
      "Epoch 32/100, Test Accuracy: 99.00% Loss: 134.85909198945768, Correct: 99, All: 100 \n",
      "Epoch 33/100, Test Accuracy: 99.00% Loss: 138.67452318117932, Correct: 99, All: 100 \n",
      "Epoch 34/100, Test Accuracy: 99.00% Loss: 142.4692464609878, Correct: 99, All: 100 \n",
      "Epoch 35/100, Test Accuracy: 99.00% Loss: 146.23786121680752, Correct: 99, All: 100 \n",
      "Epoch 36/100, Test Accuracy: 99.00% Loss: 149.97593501247044, Correct: 99, All: 100 \n",
      "Epoch 37/100, Test Accuracy: 99.00% Loss: 153.6798719651719, Correct: 99, All: 100 \n",
      "Epoch 38/100, Test Accuracy: 99.00% Loss: 157.34679451786928, Correct: 99, All: 100 \n",
      "Epoch 39/100, Test Accuracy: 99.00% Loss: 160.97443864746597, Correct: 99, All: 100 \n",
      "Epoch 40/100, Test Accuracy: 99.00% Loss: 164.56106193177868, Correct: 99, All: 100 \n",
      "Epoch 41/100, Test Accuracy: 99.00% Loss: 168.10536354390433, Correct: 99, All: 100 \n",
      "Epoch 42/100, Test Accuracy: 99.00% Loss: 171.6064150686774, Correct: 99, All: 100 \n",
      "Epoch 43/100, Test Accuracy: 99.00% Loss: 175.0636009811732, Correct: 99, All: 100 \n",
      "Epoch 44/100, Test Accuracy: 99.00% Loss: 178.47656764778398, Correct: 99, All: 100 \n",
      "Epoch 45/100, Test Accuracy: 99.00% Loss: 181.8451797756057, Correct: 99, All: 100 \n",
      "Epoch 46/100, Test Accuracy: 99.00% Loss: 185.1694833249136, Correct: 99, All: 100 \n",
      "Epoch 47/100, Test Accuracy: 99.00% Loss: 188.4496739986104, Correct: 99, All: 100 \n",
      "Epoch 48/100, Test Accuracy: 99.00% Loss: 191.68607052296215, Correct: 99, All: 100 \n",
      "Epoch 49/100, Test Accuracy: 99.00% Loss: 194.87909203038947, Correct: 99, All: 100 \n",
      "Epoch 50/100, Test Accuracy: 99.00% Loss: 198.02923894459633, Correct: 99, All: 100 \n",
      "Epoch 51/100, Test Accuracy: 99.00% Loss: 201.13707684946743, Correct: 99, All: 100 \n",
      "Epoch 52/100, Test Accuracy: 99.00% Loss: 204.20322289551797, Correct: 99, All: 100 \n",
      "Epoch 53/100, Test Accuracy: 99.00% Loss: 207.22833436138623, Correct: 99, All: 100 \n",
      "Epoch 54/100, Test Accuracy: 99.00% Loss: 210.2130990434598, Correct: 99, All: 100 \n",
      "Epoch 55/100, Test Accuracy: 99.00% Loss: 213.15822719488918, Correct: 99, All: 100 \n",
      "Epoch 56/100, Test Accuracy: 99.00% Loss: 216.06444477675794, Correct: 99, All: 100 \n",
      "Epoch 57/100, Test Accuracy: 99.00% Loss: 218.9324878197919, Correct: 99, All: 100 \n",
      "Epoch 58/100, Test Accuracy: 99.00% Loss: 221.76309772547063, Correct: 99, All: 100 \n",
      "Epoch 59/100, Test Accuracy: 99.00% Loss: 224.55701736139184, Correct: 99, All: 100 \n",
      "Epoch 60/100, Test Accuracy: 99.00% Loss: 227.31498782787622, Correct: 99, All: 100 \n",
      "Epoch 61/100, Test Accuracy: 99.00% Loss: 230.03774579162183, Correct: 99, All: 100 \n",
      "Epoch 62/100, Test Accuracy: 99.00% Loss: 232.72602129818594, Correct: 99, All: 100 \n",
      "Epoch 63/100, Test Accuracy: 99.00% Loss: 235.3805359886301, Correct: 99, All: 100 \n",
      "Epoch 64/100, Test Accuracy: 99.00% Loss: 238.00200165714472, Correct: 99, All: 100 \n",
      "Epoch 65/100, Test Accuracy: 99.00% Loss: 240.59111909620248, Correct: 99, All: 100 \n",
      "Epoch 66/100, Test Accuracy: 99.00% Loss: 243.1485771840168, Correct: 99, All: 100 \n",
      "Epoch 67/100, Test Accuracy: 99.00% Loss: 245.67505217605938, Correct: 99, All: 100 \n",
      "Epoch 68/100, Test Accuracy: 100.00% Loss: 248.17120716827733, Correct: 100, All: 100 \n",
      "Epoch 69/100, Test Accuracy: 100.00% Loss: 250.6376917046409, Correct: 100, All: 100 \n",
      "Epoch 70/100, Test Accuracy: 100.00% Loss: 253.07514150586513, Correct: 100, All: 100 \n",
      "Epoch 71/100, Test Accuracy: 100.00% Loss: 255.48417829971208, Correct: 100, All: 100 \n",
      "Epoch 72/100, Test Accuracy: 100.00% Loss: 257.86540973629235, Correct: 100, All: 100 \n",
      "Epoch 73/100, Test Accuracy: 100.00% Loss: 260.2194293743331, Correct: 100, All: 100 \n",
      "Epoch 74/100, Test Accuracy: 100.00% Loss: 262.54681672652885, Correct: 100, All: 100 \n",
      "Epoch 75/100, Test Accuracy: 100.00% Loss: 264.84813735391003, Correct: 100, All: 100 \n",
      "Epoch 76/100, Test Accuracy: 100.00% Loss: 267.1239430007074, Correct: 100, All: 100 \n",
      "Epoch 77/100, Test Accuracy: 100.00% Loss: 269.3747717624881, Correct: 100, All: 100 \n",
      "Epoch 78/100, Test Accuracy: 100.00% Loss: 271.6011482814388, Correct: 100, All: 100 \n",
      "Epoch 79/100, Test Accuracy: 100.00% Loss: 273.80358396360543, Correct: 100, All: 100 \n",
      "Epoch 80/100, Test Accuracy: 100.00% Loss: 275.98257721368793, Correct: 100, All: 100 \n",
      "Epoch 81/100, Test Accuracy: 100.00% Loss: 278.138613683652, Correct: 100, All: 100 \n",
      "Epoch 82/100, Test Accuracy: 100.00% Loss: 280.2721665319961, Correct: 100, All: 100 \n",
      "Epoch 83/100, Test Accuracy: 100.00% Loss: 282.38369669097995, Correct: 100, All: 100 \n",
      "Epoch 84/100, Test Accuracy: 100.00% Loss: 284.4736531395412, Correct: 100, All: 100 \n",
      "Epoch 85/100, Test Accuracy: 100.00% Loss: 286.5424731799662, Correct: 100, All: 100 \n",
      "Epoch 86/100, Test Accuracy: 100.00% Loss: 288.59058271667925, Correct: 100, All: 100 \n",
      "Epoch 87/100, Test Accuracy: 100.00% Loss: 290.61839653576567, Correct: 100, All: 100 \n",
      "Epoch 88/100, Test Accuracy: 100.00% Loss: 292.6263185840602, Correct: 100, All: 100 \n",
      "Epoch 89/100, Test Accuracy: 100.00% Loss: 294.6147422468131, Correct: 100, All: 100 \n",
      "Epoch 90/100, Test Accuracy: 100.00% Loss: 296.58405062310555, Correct: 100, All: 100 \n",
      "Epoch 91/100, Test Accuracy: 100.00% Loss: 298.53461679832054, Correct: 100, All: 100 \n",
      "Epoch 92/100, Test Accuracy: 100.00% Loss: 300.4668041130871, Correct: 100, All: 100 \n",
      "Epoch 93/100, Test Accuracy: 100.00% Loss: 302.3809664282205, Correct: 100, All: 100 \n",
      "Epoch 94/100, Test Accuracy: 100.00% Loss: 304.2774483852604, Correct: 100, All: 100 \n",
      "Epoch 95/100, Test Accuracy: 100.00% Loss: 306.156585662289, Correct: 100, All: 100 \n",
      "Epoch 96/100, Test Accuracy: 100.00% Loss: 308.01870522476645, Correct: 100, All: 100 \n",
      "Epoch 97/100, Test Accuracy: 100.00% Loss: 309.86412557118246, Correct: 100, All: 100 \n",
      "Epoch 98/100, Test Accuracy: 100.00% Loss: 311.6931569733672, Correct: 100, All: 100 \n",
      "Epoch 99/100, Test Accuracy: 100.00% Loss: 313.5061017113445, Correct: 100, All: 100 \n",
      "Epoch 100/100, Test Accuracy: 100.00% Loss: 315.30325430264793, Correct: 100, All: 100 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.simple.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.simple.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 2\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nn = NeuralNetwork(input_size = 2, output_size = num_classes, hidden_size = 8, hidden_layers_count = 1, num_epochs = 100, inner_activation_function = ActivationFuction.SIGMOID)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Test Accuracy: 99.29% Loss: 13144.543980401108, Correct: 9929, All: 10000 \n",
      "Epoch 2/20, Test Accuracy: 99.62% Loss: 23370.381661655236, Correct: 9962, All: 10000 \n",
      "Epoch 3/20, Test Accuracy: 99.61% Loss: 30042.126455795216, Correct: 9961, All: 10000 \n",
      "Epoch 4/20, Test Accuracy: 99.64% Loss: 34948.087385028855, Correct: 9964, All: 10000 \n",
      "Epoch 5/20, Test Accuracy: 99.63% Loss: 38843.42699606973, Correct: 9963, All: 10000 \n",
      "Epoch 6/20, Test Accuracy: 99.65% Loss: 42084.93332066136, Correct: 9965, All: 10000 \n",
      "Epoch 7/20, Test Accuracy: 99.65% Loss: 44867.11396571289, Correct: 9965, All: 10000 \n",
      "Epoch 8/20, Test Accuracy: 99.66% Loss: 47307.489343299065, Correct: 9966, All: 10000 \n",
      "Epoch 9/20, Test Accuracy: 99.65% Loss: 49482.56977422134, Correct: 9965, All: 10000 \n",
      "Epoch 10/20, Test Accuracy: 99.65% Loss: 51445.05000707353, Correct: 9965, All: 10000 \n",
      "Epoch 11/20, Test Accuracy: 99.64% Loss: 53232.84779439861, Correct: 9964, All: 10000 \n",
      "Epoch 12/20, Test Accuracy: 99.63% Loss: 54874.219636912996, Correct: 9963, All: 10000 \n",
      "Epoch 13/20, Test Accuracy: 99.62% Loss: 56390.83189654871, Correct: 9962, All: 10000 \n",
      "Epoch 14/20, Test Accuracy: 99.62% Loss: 57799.6952440829, Correct: 9962, All: 10000 \n",
      "Epoch 15/20, Test Accuracy: 99.61% Loss: 59114.432903194, Correct: 9961, All: 10000 \n",
      "Epoch 16/20, Test Accuracy: 99.61% Loss: 60346.14080157422, Correct: 9961, All: 10000 \n",
      "Epoch 17/20, Test Accuracy: 99.60% Loss: 61503.988185840564, Correct: 9960, All: 10000 \n",
      "Epoch 18/20, Test Accuracy: 99.59% Loss: 62595.64775849769, Correct: 9959, All: 10000 \n",
      "Epoch 19/20, Test Accuracy: 99.58% Loss: 63627.61063476676, Correct: 9958, All: 10000 \n",
      "Epoch 20/20, Test Accuracy: 99.58% Loss: 64605.42152289022, Correct: 9958, All: 10000 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.simple.test.10000.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.simple.train.10000.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 2\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nn = NeuralNetwork(input_size = 2, output_size = num_classes, hidden_size = 8, hidden_layers_count = 2, num_epochs = 20, inner_activation_function = ActivationFuction.SIGMOID)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Test Accuracy: 33.33% Loss: 133827.55862143144, Correct: 10000, All: 30000 \n",
      "Epoch 2/50, Test Accuracy: 33.33% Loss: 136177.99542176604, Correct: 10000, All: 30000 \n",
      "Epoch 3/50, Test Accuracy: 33.33% Loss: 141890.10915416034, Correct: 10000, All: 30000 \n",
      "Epoch 4/50, Test Accuracy: 33.33% Loss: 150685.89612457744, Correct: 10000, All: 30000 \n",
      "Epoch 5/50, Test Accuracy: 33.33% Loss: 159864.30123881265, Correct: 10000, All: 30000 \n",
      "Epoch 6/50, Test Accuracy: 33.33% Loss: 168111.72302442804, Correct: 10000, All: 30000 \n",
      "Epoch 7/50, Test Accuracy: 33.35% Loss: 175295.69288388942, Correct: 10004, All: 30000 \n",
      "Epoch 8/50, Test Accuracy: 34.01% Loss: 181541.59685305684, Correct: 10202, All: 30000 \n",
      "Epoch 9/50, Test Accuracy: 35.49% Loss: 187018.0768503781, Correct: 10646, All: 30000 \n",
      "Epoch 10/50, Test Accuracy: 36.90% Loss: 191906.51952974027, Correct: 11071, All: 30000 \n",
      "Epoch 11/50, Test Accuracy: 38.12% Loss: 196366.13911099656, Correct: 11435, All: 30000 \n",
      "Epoch 12/50, Test Accuracy: 39.03% Loss: 200528.4210274837, Correct: 11708, All: 30000 \n",
      "Epoch 13/50, Test Accuracy: 39.58% Loss: 204506.05508867404, Correct: 11873, All: 30000 \n",
      "Epoch 14/50, Test Accuracy: 40.10% Loss: 208397.01186970287, Correct: 12030, All: 30000 \n",
      "Epoch 15/50, Test Accuracy: 40.41% Loss: 212276.9877992867, Correct: 12124, All: 30000 \n",
      "Epoch 16/50, Test Accuracy: 40.63% Loss: 216183.1066063487, Correct: 12189, All: 30000 \n",
      "Epoch 17/50, Test Accuracy: 40.79% Loss: 220101.68999725248, Correct: 12238, All: 30000 \n",
      "Epoch 18/50, Test Accuracy: 40.92% Loss: 223977.09906680856, Correct: 12275, All: 30000 \n",
      "Epoch 19/50, Test Accuracy: 41.08% Loss: 227742.33831427665, Correct: 12325, All: 30000 \n",
      "Epoch 20/50, Test Accuracy: 41.21% Loss: 231347.533338838, Correct: 12364, All: 30000 \n",
      "Epoch 21/50, Test Accuracy: 41.39% Loss: 234766.10076019942, Correct: 12416, All: 30000 \n",
      "Epoch 22/50, Test Accuracy: 41.55% Loss: 237984.2886879612, Correct: 12464, All: 30000 \n",
      "Epoch 23/50, Test Accuracy: 41.78% Loss: 240989.9267282092, Correct: 12533, All: 30000 \n",
      "Epoch 24/50, Test Accuracy: 41.96% Loss: 243767.59920574605, Correct: 12588, All: 30000 \n",
      "Epoch 25/50, Test Accuracy: 42.15% Loss: 246299.01665794218, Correct: 12644, All: 30000 \n",
      "Epoch 26/50, Test Accuracy: 42.26% Loss: 248565.4678374652, Correct: 12679, All: 30000 \n",
      "Epoch 27/50, Test Accuracy: 42.40% Loss: 250550.37298031562, Correct: 12721, All: 30000 \n",
      "Epoch 28/50, Test Accuracy: 42.55% Loss: 252241.184637315, Correct: 12766, All: 30000 \n",
      "Epoch 29/50, Test Accuracy: 42.63% Loss: 253630.5209067661, Correct: 12790, All: 30000 \n",
      "Epoch 30/50, Test Accuracy: 42.70% Loss: 254716.64317145152, Correct: 12811, All: 30000 \n",
      "Epoch 31/50, Test Accuracy: 42.74% Loss: 255503.42893169387, Correct: 12823, All: 30000 \n",
      "Epoch 32/50, Test Accuracy: 42.81% Loss: 255999.9600964776, Correct: 12843, All: 30000 \n",
      "Epoch 33/50, Test Accuracy: 42.88% Loss: 256219.80182947245, Correct: 12863, All: 30000 \n",
      "Epoch 34/50, Test Accuracy: 42.89% Loss: 256180.01391836104, Correct: 12868, All: 30000 \n",
      "Epoch 35/50, Test Accuracy: 42.93% Loss: 255899.93322947138, Correct: 12880, All: 30000 \n",
      "Epoch 36/50, Test Accuracy: 42.95% Loss: 255399.80131799303, Correct: 12886, All: 30000 \n",
      "Epoch 37/50, Test Accuracy: 42.97% Loss: 254699.38048876278, Correct: 12890, All: 30000 \n",
      "Epoch 38/50, Test Accuracy: 42.98% Loss: 253816.78028961248, Correct: 12894, All: 30000 \n",
      "Epoch 39/50, Test Accuracy: 42.99% Loss: 252767.7662334607, Correct: 12897, All: 30000 \n",
      "Epoch 40/50, Test Accuracy: 43.01% Loss: 251565.807064149, Correct: 12902, All: 30000 \n",
      "Epoch 41/50, Test Accuracy: 43.03% Loss: 250223.01765181698, Correct: 12909, All: 30000 \n",
      "Epoch 42/50, Test Accuracy: 43.07% Loss: 248751.97334091837, Correct: 12921, All: 30000 \n",
      "Epoch 43/50, Test Accuracy: 43.11% Loss: 247168.1212374952, Correct: 12933, All: 30000 \n",
      "Epoch 44/50, Test Accuracy: 43.16% Loss: 245492.22136554512, Correct: 12947, All: 30000 \n",
      "Epoch 45/50, Test Accuracy: 43.18% Loss: 243751.9874863589, Correct: 12954, All: 30000 \n",
      "Epoch 46/50, Test Accuracy: 43.22% Loss: 241982.0164450585, Correct: 12966, All: 30000 \n",
      "Epoch 47/50, Test Accuracy: 43.27% Loss: 240221.40108415324, Correct: 12980, All: 30000 \n",
      "Epoch 48/50, Test Accuracy: 43.31% Loss: 238509.20961867506, Correct: 12992, All: 30000 \n",
      "Epoch 49/50, Test Accuracy: 43.34% Loss: 236879.03641334103, Correct: 13003, All: 30000 \n",
      "Epoch 50/50, Test Accuracy: 43.40% Loss: 235354.47189441026, Correct: 13019, All: 30000 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.three_gauss.test.10000.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.three_gauss.train.10000.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 3\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nn = NeuralNetwork(input_size = 2, output_size = num_classes, hidden_size = 6, hidden_layers_count = 1, num_epochs = 50, inner_activation_function = ActivationFuction.SIGMOID)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Test Accuracy: 134243.47854882723\n",
      "Epoch 2/20, Test Accuracy: 133524.77838048464\n",
      "Epoch 3/20, Test Accuracy: 133266.78702831615\n",
      "Epoch 4/20, Test Accuracy: 133173.03395099868\n",
      "Epoch 5/20, Test Accuracy: 133138.80841236367\n",
      "Epoch 6/20, Test Accuracy: 133126.2929665212\n",
      "Epoch 7/20, Test Accuracy: 133121.71354422753\n",
      "Epoch 8/20, Test Accuracy: 133120.03754670746\n",
      "Epoch 9/20, Test Accuracy: 133119.42410677206\n",
      "Epoch 10/20, Test Accuracy: 133119.19957185013\n",
      "Epoch 11/20, Test Accuracy: 133119.11738533387\n",
      "Epoch 12/20, Test Accuracy: 133119.08730248164\n",
      "Epoch 13/20, Test Accuracy: 133119.07629119421\n",
      "Epoch 14/20, Test Accuracy: 133119.0722607082\n",
      "Epoch 15/20, Test Accuracy: 133119.07078542002\n",
      "Epoch 16/20, Test Accuracy: 133119.07024541692\n",
      "Epoch 17/20, Test Accuracy: 133119.0700477583\n",
      "Epoch 18/20, Test Accuracy: 133119.06997540893\n",
      "Epoch 19/20, Test Accuracy: 133119.0699489267\n",
      "Epoch 20/20, Test Accuracy: 133119.0699392333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"regression/data.cube.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"regression/data.cube.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[\"x\"])\n",
    "train_results = np.array(train[\"y\"])\n",
    "test_vectors = np.array(test[\"x\"])\n",
    "test_results = np.array(test[\"y\"])\n",
    "\n",
    "nn = NeuralNetwork(hidden_size = 6, hidden_layers_count = 1, num_epochs = 20, inner_activation_function = ActivationFuction.RELU, problem = Problem.Regression)\n",
    "nn.train_and_check_acc(train_vectors, train_results, test_vectors, test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
