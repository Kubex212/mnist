{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "\n",
    "class Softmax():\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        x = np.clip(x, 1e-15, 1 - 1e-15)\n",
    "        e_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=0, keepdims=True)\n",
    "    \n",
    "    def compute_derivative(self, x):\n",
    "        value = self.compute(x)\n",
    "        return value * (1 - value)\n",
    "    \n",
    "class ReLU():\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_derivative(x):\n",
    "        return x > 0\n",
    "    \n",
    "class LeakyReLU:\n",
    "    @staticmethod\n",
    "    def compute(x, alpha=0.01):\n",
    "        return np.where(x >= 0, x, alpha * x)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(x, alpha=0.01):\n",
    "        return np.where(x >= 0, 1, alpha)\n",
    "    \n",
    "class Sigmoid():\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def compute_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "class CrossEntropy():\n",
    "    @staticmethod\n",
    "    def compute(y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        return - (y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        return - (y / y_pred) + (1 - y) / (1 - y_pred)\n",
    "    \n",
    "class MSE:\n",
    "    @staticmethod\n",
    "    def compute(y, y_pred):\n",
    "        return ((y - y_pred) ** 2).mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_derivative(y, y_pred):\n",
    "        return -2*(y - y_pred) / y.shape[0]\n",
    "    \n",
    "class Tanh:\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(x):\n",
    "        return 1 - x ** 2\n",
    "    \n",
    "class Linear:\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(x):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "class NeuralNetworkStructure:\n",
    "    def __init__(self, inputSize, outputSize, hiddenLayerSizes, hiddenLayerFunction, outputLayerFunction):\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenLayerSizes = hiddenLayerSizes\n",
    "        self.layersSizes = hiddenLayerSizes + [outputSize]\n",
    "        self.activationFunction = [hiddenLayerFunction] * len(hiddenLayerSizes) + [outputLayerFunction]\n",
    "        self.layerInput = [None] * len(self.layersSizes)\n",
    "        self.layerOutput = [None] * len(self.layersSizes)\n",
    "\n",
    "        self.initializeWeights()\n",
    "\n",
    "    def initializeWeights(self):\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        \n",
    "        previousLayerSize = self.inputSize\n",
    "        for layerSize in self.layersSizes:\n",
    "            self.weights.append(np.random.rand(layerSize, previousLayerSize) - 0.5)\n",
    "            self.bias.append(np.random.rand(layerSize, 1) - 0.5)\n",
    "            previousLayerSize = layerSize\n",
    "            \n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, neuralNetworkStructure, epochs, learningRate, lossFunction):\n",
    "        self.structure = neuralNetworkStructure\n",
    "        self.lossFunction = lossFunction\n",
    "        self.learningRate = learningRate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    \n",
    "    def Forward(self, X):\n",
    "        previous_layer = np.reshape(X, (X.shape[0], 1))\n",
    "        for id in range(len(self.structure.layersSizes)):\n",
    "            self.structure.layerInput[id] = self.structure.weights[id].dot(previous_layer) + self.structure.bias[id]\n",
    "            self.structure.layerOutput[id] = self.structure.activationFunction[id].compute(self.structure.layerInput[id])\n",
    "            previous_layer = self.structure.layerOutput[id]\n",
    "        return previous_layer\n",
    "    \n",
    "    \n",
    "    def Backward(self, X, ExpectedY, PredictedY):\n",
    "        previous_layer_error = self.lossFunction.compute_derivative(ExpectedY, PredictedY)\n",
    "        \n",
    "        for id in range(len(self.structure.layersSizes) -1, -1, -1):\n",
    "            previous_layer_output = self.structure.layerOutput[id - 1] if id != 0 else X\n",
    "            \n",
    "            delta = previous_layer_error * self.structure.activationFunction[id].compute_derivative(self.structure.layerOutput[id])\n",
    "            deltaW = np.dot(delta, previous_layer_output.T)\n",
    "            deltaB = delta\n",
    "            previous_layer_error = np.dot(self.structure.weights[id].T, delta)\n",
    "                                        \n",
    "            self.structure.weights[id] -= self.learningRate * deltaW\n",
    "            self.structure.bias[id] -= self.learningRate * deltaB\n",
    "    \n",
    "    \n",
    "    def Train(self, X, ExpectedY):\n",
    "    \n",
    "        X = np.reshape(X, (X.shape[0], 1))\n",
    "        ExpectedY = np.reshape(ExpectedY, (ExpectedY.shape[0], 1))\n",
    "    \n",
    "        predictedY = self.Forward(X)\n",
    "        self.Backward(X, ExpectedY, predictedY)\n",
    "            \n",
    "\n",
    "    def Test(self, train_inputs, train_results, test_inputs, test_results):\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(len(train_inputs)):\n",
    "              self.Train(train_inputs[i], train_results[i])\n",
    "            \n",
    "            correct = 0\n",
    "            for i in range(len(test_inputs)):\n",
    "                predictedY = self.Forward(np.reshape(test_inputs[i], (-1, 1)))\n",
    "\n",
    "                if np.argmax(predictedY) == np.argmax(test_results[i]):\n",
    "                    correct += 1\n",
    "            \n",
    "            test_accuracy = correct / len(test_inputs)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Test Accuracy: {test_accuracy * 100:.2f}% Correct: {correct}, All: {len(test_inputs)} \")            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#class NeuralNetworkClassificator(NeuralNetwork): \n",
    "    \n",
    "    \n",
    "    \n",
    "#class NeuralNetworkRegressor(NeuralNetwork): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Test Accuracy: 53.00% Correct: 53, All: 100 \n",
      "Epoch 2/100, Test Accuracy: 86.00% Correct: 86, All: 100 \n",
      "Epoch 3/100, Test Accuracy: 92.00% Correct: 92, All: 100 \n",
      "Epoch 4/100, Test Accuracy: 93.00% Correct: 93, All: 100 \n",
      "Epoch 5/100, Test Accuracy: 95.00% Correct: 95, All: 100 \n",
      "Epoch 6/100, Test Accuracy: 96.00% Correct: 96, All: 100 \n",
      "Epoch 7/100, Test Accuracy: 97.00% Correct: 97, All: 100 \n",
      "Epoch 8/100, Test Accuracy: 99.00% Correct: 99, All: 100 \n",
      "Epoch 9/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 10/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 11/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 12/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 13/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 14/100, Test Accuracy: 99.00% Correct: 99, All: 100 \n",
      "Epoch 15/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 16/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 17/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 18/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 19/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 20/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 21/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 22/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 23/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 24/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 25/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 26/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 27/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 28/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 29/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 30/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 31/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 32/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 33/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 34/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 35/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 36/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 37/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 38/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 39/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 40/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 41/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 42/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 43/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 44/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 45/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 46/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 47/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 48/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 49/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 50/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 51/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 52/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 53/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 54/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 55/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 56/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 57/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 58/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 59/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 60/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 61/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 62/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 63/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 64/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 65/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 66/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 67/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 68/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 69/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 70/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 71/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 72/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 73/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 74/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 75/100, Test Accuracy: 98.00% Correct: 98, All: 100 \n",
      "Epoch 76/100, Test Accuracy: 99.00% Correct: 99, All: 100 \n",
      "Epoch 77/100, Test Accuracy: 99.00% Correct: 99, All: 100 \n",
      "Epoch 78/100, Test Accuracy: 99.00% Correct: 99, All: 100 \n",
      "Epoch 79/100, Test Accuracy: 99.00% Correct: 99, All: 100 \n",
      "Epoch 80/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 81/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 82/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 83/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 84/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 85/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 86/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 87/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 88/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 89/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 90/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 91/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 92/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 93/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 94/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 95/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 96/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 97/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 98/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 99/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n",
      "Epoch 100/100, Test Accuracy: 100.00% Correct: 100, All: 100 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.simple.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.simple.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 2\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nnS = NeuralNetworkStructure(\n",
    "    inputSize = 2, \n",
    "    outputSize = 2, \n",
    "    hiddenLayerSizes = [8], \n",
    "    hiddenLayerFunction = Sigmoid(), \n",
    "    outputLayerFunction = Softmax())\n",
    "\n",
    "nn = NeuralNetwork(  \n",
    "    epochs = 100, \n",
    "    learningRate = 0.01,\n",
    "    neuralNetworkStructure = nnS,\n",
    "    lossFunction = CrossEntropy())\n",
    "\n",
    "nn.Test(train_vectors, train_results, test_vectors, test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
