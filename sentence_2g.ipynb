{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "\n",
    "class Softmax():\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        x = np.clip(x, 1e-15, 1 - 1e-15)\n",
    "        e_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=0, keepdims=True)\n",
    "    \n",
    "    def compute_derivative(self, x):\n",
    "        value = self.compute(x)\n",
    "        return value * (1 - value)\n",
    "    \n",
    "class ReLU():\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_derivative(x):\n",
    "        return x > 0\n",
    "    \n",
    "class LeakyReLU:\n",
    "    @staticmethod\n",
    "    def compute(x, alpha=0.01):\n",
    "        return np.where(x >= 0, x, alpha * x)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(x, alpha=0.01):\n",
    "        return np.where(x >= 0, 1, alpha)\n",
    "    \n",
    "class Sigmoid():\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def compute_derivative(self, x):\n",
    "        return self.compute(x) * (1 - self.compute(x))\n",
    "    \n",
    "class CrossEntropy():\n",
    "    @staticmethod\n",
    "    def compute(y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        return - (y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        return - (y / y_pred) + (1 - y) / (1 - y_pred)\n",
    "    \n",
    "class MSE:\n",
    "    @staticmethod\n",
    "    def compute(y, y_pred):\n",
    "        return ((y - y_pred) ** 2).mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_derivative(y, y_pred):\n",
    "        return -2*(y - y_pred) / y.shape[0]\n",
    "    \n",
    "class Tanh:\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(x):\n",
    "        return 1 - x ** 2\n",
    "    \n",
    "class Linear:\n",
    "    @staticmethod\n",
    "    def compute(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_derivative(x):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "class NeuralNetworkStructure:\n",
    "    def __init__(self, inputSize, outputSize, hiddenLayerSizes, hiddenLayerFunction, outputLayerFunction):\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenLayerSizes = hiddenLayerSizes\n",
    "        self.layersSizes = hiddenLayerSizes + [outputSize]\n",
    "        self.activationFunction = [hiddenLayerFunction] * len(hiddenLayerSizes) + [outputLayerFunction]\n",
    "        self.layerInput = [None] * len(self.layersSizes)\n",
    "        self.layerOutput = [None] * len(self.layersSizes)\n",
    "\n",
    "        self.initializeWeights()\n",
    "\n",
    "    def initializeWeights(self):\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        \n",
    "        previousLayerSize = self.inputSize\n",
    "        for layerSize in self.layersSizes:\n",
    "            self.weights.append(np.random.rand(layerSize, previousLayerSize) - 0.5)\n",
    "            self.bias.append(np.random.rand((layerSize)) - 0.5)\n",
    "            previousLayerSize = layerSize\n",
    "            \n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, neuralNetworkStructure, epochs, learningRate, lossFunction):\n",
    "        self.structure = neuralNetworkStructure\n",
    "        self.lossFunction = lossFunction\n",
    "        self.learningRate = learningRate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    \n",
    "    def Forward(self, X):\n",
    "        previous_layer = X\n",
    "        for id in range(len(self.structure.layersSizes)):\n",
    "            self.structure.layerInput[id] = self.structure.weights[id].dot(previous_layer) + self.structure.bias[id]\n",
    "            self.structure.layerOutput[id] = self.structure.activationFunction[id].compute(self.structure.layerInput[id])\n",
    "            previous_layer = self.structure.layerOutput[id]\n",
    "        return previous_layer\n",
    "    \n",
    "    \n",
    "    def Backward(self, X, ExpectedY, PredictedY):\n",
    "        \n",
    "        previous_layer_error = self.lossFunction.compute_derivative(ExpectedY, PredictedY)\n",
    "        \n",
    "        for id in range(len(self.structure.layersSizes) -1, -1, -1):\n",
    "            previous_layer_output = self.structure.layerOutput[id - 1] if id != 0 else X\n",
    "            \n",
    "            delta = previous_layer_error * self.structure.activationFunction[id].compute_derivative(self.structure.layerOutput[id])\n",
    "            previous_layer_error = self.structure.weights[id].T.dot(delta)\n",
    "                                        \n",
    "            self.structure.weights[id] -= self.learningRate * np.reshape( delta, (delta.shape[0], 1)) *np.reshape(previous_layer_output, (1, previous_layer_output.shape[0]))\n",
    "            self.structure.bias[id] -= self.learningRate * delta\n",
    "    \n",
    "    \n",
    "    def Train(self, X, ExpectedY):\n",
    "    \n",
    "        predictedY = self.Forward(X)\n",
    "        self.Backward(X, ExpectedY, predictedY)\n",
    "            \n",
    "\n",
    "    def Test(self, train_inputs, train_results, test_inputs, test_results):\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(len(train_inputs)):\n",
    "                self.Train(train_inputs[i], train_results[i])\n",
    "            \n",
    "            correct = 0\n",
    "            for i in range(len(test_inputs)):\n",
    "                predictedY = self.Forward(train_inputs[i])\n",
    "\n",
    "                if np.argmax(predictedY) == np.argmax(test_results[i]):\n",
    "                    correct += 1\n",
    "            \n",
    "            test_accuracy = correct / len(test_inputs)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Test Accuracy: {test_accuracy * 100:.2f}% Correct: {correct}, All: {len(test_inputs)} \")            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#class NeuralNetworkClassificator(NeuralNetwork): \n",
    "    \n",
    "    \n",
    "    \n",
    "#class NeuralNetworkRegressor(NeuralNetwork): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0490893  -0.04042218]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"classification/data.simple.test.100.csv\", sep=\",\")\n",
    "train = pd.read_csv(\"classification/data.simple.train.100.csv\", sep=\",\")\n",
    "\n",
    "train_vectors = np.array(train[[\"x\", \"y\"]])\n",
    "train_results = np.array(train[\"cls\"] - 1)\n",
    "test_vectors = np.array(test[[\"x\", \"y\"]])\n",
    "test_results = np.array(test[\"cls\"] - 1)\n",
    "\n",
    "num_classes = 2\n",
    "train_results = np.eye(num_classes)[train_results]\n",
    "test_results = np.eye(num_classes)[test_results]\n",
    "\n",
    "nnS = NeuralNetworkStructure(\n",
    "    inputSize = 2, \n",
    "    outputSize = 2, \n",
    "    hiddenLayerSizes = [4], \n",
    "    hiddenLayerFunction = Sigmoid(), \n",
    "    outputLayerFunction = Sigmoid())\n",
    "\n",
    "nn = NeuralNetwork(  \n",
    "    epochs = 30, \n",
    "    learningRate = 0.1,\n",
    "    neuralNetworkStructure = nnS,\n",
    "    lossFunction = CrossEntropy())\n",
    "\n",
    "nn.Test(train_vectors, train_results, test_vectors, test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
